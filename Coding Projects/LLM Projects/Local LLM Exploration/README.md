# Local LLM Exploration: Gemma, Llama 2, and Persistent Memory Prototyping

This project explores the integration of local large language models (LLMs) with a focus on persistent memory systems, providing the foundation for adaptive AI-driven applications. Specifically, I've experimented with models like **Gemma** and **Llama 2** using **Ollama**.

## Key Features

- **Persistent Chat History**: A C++ prototype designed to track and store user interaction history, allowing the system to "remember" context over time.
- **Adaptive Learning Framework**: The groundwork for a system that could dynamically adjust its responses based on prior interactions, showcasing the potential for conversational AI to evolve with user input.
- **Model Integration**: Incorporates models like Gemma and Llama 2 to simulate interactive conversations, laying the foundation for more advanced AI applications.

## Technologies Used

- **C++**: The core implementation language for building the persistent memory system.
- **Ollama**: Used to experiment with local LLMs (Gemma, Llama 2).
- **JSON File I/O**: For saving and loading chat history to/from files.
  
## Future Plans

- **Lightweight Fine-Tuning**: Explore ways to fine-tune the models to better retain user context and adapt responses.
- **Interactive AI Tutoring**: Expand the chat history system into a fully-fledged AI tutor application that adapts to user needs and keeps track of their learning progress.
